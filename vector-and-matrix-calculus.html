
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Vector and Matrix Calculus &#8212; Neural Networks by Hand</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="The Chain Rule" href="chain-rule.html" />
    <link rel="prev" title="Linear Algebra" href="linear-algebra.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Neural Networks by Hand</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Neural Networks by Hand
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Prerequesites
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="gradient-descent.html">
   Gradient Descent
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear-algebra.html">
   Linear Algebra
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Vector and Matrix Calculus
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chain-rule.html">
   The Chain Rule
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Building Blocks
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="neurons-and-networks.html">
   Neurons and Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="back-propagation.html">
   Backward Propagation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="activation-functions.html">
   Activation Functions and their Derivatives
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cost-functions.html">
   Cost Functions and their Derivatives
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="softmax.html">
   Softmax and Cross-Entropy
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Putting it all together
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="feedforward-neural-network.html">
   Feedforward Neural Networks
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/philswatton/neural-networks-by-hand"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/philswatton/neural-networks-by-hand/issues/new?title=Issue%20on%20page%20%2Fvector-and-matrix-calculus.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/vector-and-matrix-calculus.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#motivation-partial-derivatives">
   Motivation: Partial Derivatives
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#generalising-the-gradient">
   Generalising the Gradient
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#motivation-vectors-and-vectors">
   Motivation: Vectors and Vectors
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#generalising-the-jacobian">
   Generalising the Jacobian
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#some-rules-of-thumb">
   Some Rules of Thumb
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-note-on-jacobians">
   A Note on Jacobians
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Vector and Matrix Calculus</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#motivation-partial-derivatives">
   Motivation: Partial Derivatives
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#generalising-the-gradient">
   Generalising the Gradient
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#motivation-vectors-and-vectors">
   Motivation: Vectors and Vectors
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#generalising-the-jacobian">
   Generalising the Jacobian
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#some-rules-of-thumb">
   Some Rules of Thumb
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-note-on-jacobians">
   A Note on Jacobians
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="vector-and-matrix-calculus">
<h1>Vector and Matrix Calculus<a class="headerlink" href="#vector-and-matrix-calculus" title="Permalink to this headline">#</a></h1>
<p>Since we need derivatives for gradient descent, and since we’re representing our neural network in matrix form, we’re going to need some extra rules of calculus above and beyond those used for scalar calculus.</p>
<p>Foruntately, just as vectors matrices are a way of organising numbers and equations, so too is vector and matrix calculus a way of organising derivatives (amongst other things). It’s good however to be aware of the way in which we’d expect our derivatives to be organised, as this will be a useful reference point down the line.</p>
<section id="motivation-partial-derivatives">
<h2>Motivation: Partial Derivatives<a class="headerlink" href="#motivation-partial-derivatives" title="Permalink to this headline">#</a></h2>
<p>Consider a function <span class="math notranslate nohighlight">\(f\)</span> with two input variables, <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(z\)</span>:</p>
<div class="math notranslate nohighlight">
\[ f(x,z) = 3x^2z \]</div>
<p>We can take the partial derivative with respect to <span class="math notranslate nohighlight">\(x\)</span>:</p>
<div class="math notranslate nohighlight">
\[ \frac{\partial}{\partial x} = 6xz \]</div>
<p>And we can take the partial derivative with respect to <span class="math notranslate nohighlight">\(z\)</span>:</p>
<div class="math notranslate nohighlight">
\[ \frac{\partial f(x,z)}{\partial z} = 3x^2 \]</div>
<p>If we wish to organise our partial derivatives, we can store them in a vector, which we call the <strong>gradient</strong> of <span class="math notranslate nohighlight">\(f(x,z)\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split} \nabla f(x,z) = \begin{bmatrix} 6xz \\ 3x^2 \end{bmatrix} \end{split}\]</div>
<p>In general, we can move the use of vectors (and matrices) when we wish to start organising our derivatives in this fashion. In this light, vector and matrix calculus represent a notational system for <strong>multivariable calculus</strong>.</p>
</section>
<section id="generalising-the-gradient">
<h2>Generalising the Gradient<a class="headerlink" href="#generalising-the-gradient" title="Permalink to this headline">#</a></h2>
<p>In the case above, if we place <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(z\)</span> in a vector, we are taking the derivative of a scalar with respect to a vector. The outcome is two partial derivatives, which are also a vector. We can generalise this to say that the derivative of a scalar <span class="math notranslate nohighlight">\(y\)</span> with respect to an <span class="math notranslate nohighlight">\(n\)</span>-length vector <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span> will also be an <span class="math notranslate nohighlight">\(n\)</span>-length vector of derivatives:</p>
<div class="math notranslate nohighlight">
\[\begin{split} \frac{\partial y}{\partial \boldsymbol{x}} = \begin{bmatrix} \frac{\partial y}{\partial x_1} \\ \vdots \\ \frac{\partial y}{\partial x_n} \end{bmatrix} \end{split}\]</div>
<p>We call this vector the <em>gradient</em> of <span class="math notranslate nohighlight">\(y\)</span>.</p>
</section>
<section id="motivation-vectors-and-vectors">
<h2>Motivation: Vectors and Vectors<a class="headerlink" href="#motivation-vectors-and-vectors" title="Permalink to this headline">#</a></h2>
<p>We now consider the case where in addition to <span class="math notranslate nohighlight">\(f(x,z)\)</span> above, we have a second function <span class="math notranslate nohighlight">\(g(x,y)\)</span>:</p>
<div class="math notranslate nohighlight">
\[ g(x,z) = 2x + y^8 \]</div>
<p>As before, we store the partial derivatives of <span class="math notranslate nohighlight">\(g(x,z)\)</span> in a vector:</p>
<div class="math notranslate nohighlight">
\[\begin{split} \nabla g(x,z) = \begin{bmatrix} \frac{\partial g(x,z)}{\partial x} \\ \frac{\partial g(x,z)}{\partial z} \end{bmatrix} \end{split}\]</div>
<p>However, in combination with <span class="math notranslate nohighlight">\(f(x,z)\)</span> we now have two vectors of partial derivatives. If we store <span class="math notranslate nohighlight">\(f(x,z)\)</span> in a vector with <span class="math notranslate nohighlight">\(g(x,z)\)</span>, then take the derivative of this vector with respect to the vector storing <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(z\)</span>, we obtain a matrix <span class="math notranslate nohighlight">\(\boldsymbol{J}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\boldsymbol{J} = \begin{bmatrix} \nabla f(x,z) \\ \nabla g(x,z) \end{bmatrix} = \begin{bmatrix} \frac{\partial f(x,z)}{\partial x} &amp; \frac{\partial f(x,z)}{\partial z} \\ \frac{\partial g(x,z)}{\partial x} &amp; \frac{\partial g(x,z)}{\partial z} \end{bmatrix} = \begin{bmatrix} 6xz &amp; 3x^2 \\ 2 &amp; 8z^7 \end{bmatrix}
\end{split}\]</div>
<p>This matrix is known as the <strong>Jacobian</strong>.</p>
<p>Note that here, the Jacobian is presented in the <em>numerator layout</em> (i.e numerator on rows). However, in some contexts it will be presented in <em>denominator layout</em>.</p>
</section>
<section id="generalising-the-jacobian">
<h2>Generalising the Jacobian<a class="headerlink" href="#generalising-the-jacobian" title="Permalink to this headline">#</a></h2>
<p>As before, we can generalise the notion of deriving a vector with respect to a vector beyond the simple example.</p>
<p>Suppose we have an <span class="math notranslate nohighlight">\(n\)</span>-length vector of functions <span class="math notranslate nohighlight">\(\boldsymbol{f}\)</span>, and an <span class="math notranslate nohighlight">\(m\)</span>-length vector of variables <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span>. The derivative of <span class="math notranslate nohighlight">\(\boldsymbol{f}\)</span> with respect to <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span> is then:</p>
<div class="math notranslate nohighlight">
\[\begin{split} \boldsymbol{J} = \begin{bmatrix} \frac{\partial \boldsymbol{f}}{\partial x_1} &amp; \cdots &amp; \frac{\partial \boldsymbol{f}}{\partial x_n} \end{bmatrix} = \begin{bmatrix} \nabla^T f_1 \\ \vdots \\ \nabla^T f_m \end{bmatrix} = \begin{bmatrix} \frac{\partial f_1}{\partial x_1} &amp; \cdots &amp; \frac{\partial f_1}{\partial x_n} \\ \vdots &amp; \ddots &amp; \vdots \\ \frac{\partial f_m}{\partial x_1} &amp; \cdots &amp; \frac{\partial f_m}{\partial x_n} \end{bmatrix}  \end{split}\]</div>
<p>Where <span class="math notranslate nohighlight">\(\boldsymbol{J}\)</span> is an <span class="math notranslate nohighlight">\(m \times n\)</span> matrix, and <span class="math notranslate nohighlight">\(\Delta^T f_m\)</span> is the transpose (i.e. row vector) of the gradient of <span class="math notranslate nohighlight">\(f_m\)</span>.</p>
</section>
<section id="some-rules-of-thumb">
<h2>Some Rules of Thumb<a class="headerlink" href="#some-rules-of-thumb" title="Permalink to this headline">#</a></h2>
<p>There’s a pattern slowly emerging here:</p>
<ul class="simple">
<li><p>The derivative of a scalar with respect to a vector is a vector of the same size</p></li>
<li><p>The derviatve of a vector of length <span class="math notranslate nohighlight">\(n\)</span> with respect to a vector of length <span class="math notranslate nohighlight">\(m\)</span> is a matrix of size <span class="math notranslate nohighlight">\(m \times n\)</span></p></li>
<li><p>The derivative of a scalar with respect to an <span class="math notranslate nohighlight">\(m \times n\)</span> matrix is another <span class="math notranslate nohighlight">\(m \times n\)</span> matrix</p></li>
</ul>
<p>And so on. This is useful to have in mind: one simple way to check a solution to a problem is to see if these rules are satisfied. The pattern still holds for e.g. the derviative of a vector with respect to a matrix - the output for this is a tensor, which is a multidimensional generalisation of matrices. That’s beyond this notebook though!</p>
</section>
<section id="a-note-on-jacobians">
<h2>A Note on Jacobians<a class="headerlink" href="#a-note-on-jacobians" title="Permalink to this headline">#</a></h2>
<p>In many applications, Jacobian matrices turn out to be square matrices (i.e. <span class="math notranslate nohighlight">\(m=n\)</span>), with off-diagonal entries of 0.</p>
<p>When the matrix is square, whether the off-diagonal elements are 0 or not depends on whether we are taking the derivative of a vector <em>element-wise binary operation</em>. Using the notation from <em>The Matrix Calculus You Need</em> (see intro), we denote a binary operation of two vector functions as:</p>
<div class="math notranslate nohighlight">
\[ \boldsymbol{f}(\boldsymbol{w}) \bigcirc \boldsymbol{g}(\boldsymbol{x}) \]</div>
<p>In vector form, this is:</p>
<div class="math notranslate nohighlight">
\[\begin{split} \boldsymbol{y} = \begin{bmatrix} y_1 \\ \vdots \\ y_n \end{bmatrix} = \begin{bmatrix} f_1(\boldsymbol{w}) \bigcirc g_1(\boldsymbol{x}) \\ \vdots \\ f_n(\boldsymbol{w}) \bigcirc g_n(\boldsymbol{x}) \end{bmatrix} \end{split}\]</div>
<p>The generalised case of the Jacobian with respect to <span class="math notranslate nohighlight">\(\boldsymbol{w}\)</span> is</p>
<div class="math notranslate nohighlight">
\[\begin{split} \boldsymbol{J}_{\boldsymbol{w}} = \begin{bmatrix} \frac{\partial y_1}{\partial w_1} (f_1(\boldsymbol{w}) \bigcirc g_1(\boldsymbol{x})) &amp; \cdots &amp; \frac{\partial y_1}{\partial w_n} (f_1(\boldsymbol{w}) \bigcirc g_1(\boldsymbol{x})) \\ \vdots &amp; \ddots &amp; \vdots \\ \frac{\partial y_n}{\partial w_1} (f_n(\boldsymbol{w}) \bigcirc g_n(\boldsymbol{x})) &amp; \cdots &amp; \frac{\partial y_n}{\partial w_n} (f_n(\boldsymbol{w}) \bigcirc g_n(\boldsymbol{x})) \end{bmatrix} \end{split}\]</div>
<p>Of special interest is the case when <span class="math notranslate nohighlight">\(f_i\)</span> and <span class="math notranslate nohighlight">\(g_i\)</span> are constants with respect to <span class="math notranslate nohighlight">\(w_j\)</span> and <span class="math notranslate nohighlight">\(i \neq j\)</span>. In this case:</p>
<div class="math notranslate nohighlight">
\[ \frac{\partial y_i}{\partial w_j} f_i(\boldsymbol{w}) \bigcirc g_i(\boldsymbol{x}) = 0 \]</div>
<p><span class="math notranslate nohighlight">\(f_i\)</span> and <span class="math notranslate nohighlight">\(g_i\)</span> will be constant with respect to <span class="math notranslate nohighlight">\(w_j\)</span>, <span class="math notranslate nohighlight">\(i \neq j\)</span> when <span class="math notranslate nohighlight">\( \bigcirc \)</span> represents an <em>element-wise</em> binary operation.</p>
<p>An element-wise binary operation occurs when <span class="math notranslate nohighlight">\(f_i\)</span> is solely a function of <span class="math notranslate nohighlight">\(w_i\)</span> and <span class="math notranslate nohighlight">\(g_i\)</span> is solely a function of <span class="math notranslate nohighlight">\(x_i\)</span>. Some examples include vector addition, vector subtraction, element-wise multiplication of vectors, and element-wise division of vectors.</p>
<!-- This becomes useful because when we multiply a vector by a diagonal matrix, it's the equivalent of just performing element-wise multiplication between the vector and the diagonal (i.e. the output is a vector where the first element is the first element of the original times the first element of the diagonal, etc). This is a much simpler computation than when the matrix is not diagonal!  -->
<!-- ^ This is wrong: need to fix -->
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="linear-algebra.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Linear Algebra</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="chain-rule.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">The Chain Rule</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Phil Swatton<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>