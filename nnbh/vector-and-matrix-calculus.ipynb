{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector and Matrix Calculus"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation: Partial Derivatives\n",
    "\n",
    "Consider a function $f$ with two input variables, $x$ and $z$:\n",
    "\n",
    "$$ f(x,z) = 3x^2z $$\n",
    "\n",
    "We can take the partial derivative with respect to $x$:\n",
    "\n",
    "$$ \\frac{\\partial}{\\partial x} = 6xz $$\n",
    "\n",
    "And we can take the partial derivative with respect to $z$:\n",
    "\n",
    "$$ \\frac{\\partial f(x,z)}{\\partial z} = 3x^2 $$\n",
    "\n",
    "If we wish to organise our partial derivatives, we can store them in a vector, which we call the **gradient** of $f(x,z)$:\n",
    "\n",
    "$$ \\Delta f(x,z) = \\begin{bmatrix} 6xz \\\\ 3x^2 \\end{bmatrix} $$\n",
    "\n",
    "In general, we can move the use of vectors (and matrices) when we wish to start organising our derivatives in this fashion. In this light, vector and matrix calculus represent a notational system for **multivariable calculus**.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalising the Gradient\n",
    "\n",
    "In the case above, if we place $x$ and $z$ in a vector, we are taking the derivative of a scalar with respect to a vector. The outcome is two partial derivatives, which are also a vector. We can generalise this to say that the derivative of a scalar $y$ with respect to an $n$-length vector $\\boldsymbol{x}$ will also be an $n$-length vector of derivatives:\n",
    "\n",
    "$$ \\frac{\\partial y}{\\partial \\boldsymbol{x}} = \\begin{bmatrix} \\frac{\\partial y}{\\partial x_1} \\\\ \\vdots \\\\ \\frac{\\partial y}{\\partial x_n} \\end{bmatrix} $$\n",
    "\n",
    "We call this vector the *gradient* of $y$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation: Vectors and Vectors\n",
    "\n",
    "We now consider the case where in addition to $f(x,z)$ above, we have a second function $g(x,y)$:\n",
    "\n",
    "$$ g(x,z) = 2x + y^8 $$\n",
    "\n",
    "As before, we store the partial derivatives of $g(x,z)$ in a vector:\n",
    "\n",
    "$$ \\Delta g(x,z) = \\begin{bmatrix} \\frac{\\partial g(x,z)}{\\partial x} \\\\ \\frac{\\partial g(x,z)}{\\partial z} \\end{bmatrix} $$\n",
    "\n",
    "However, in combination with $f(x,z)$ we now have two vectors of partial derivatives. If we store $f(x,z)$ in a vector with $g(x,z)$, then take the derivative of this vector with respect to the vector storing $x$ and $z$, we obtain a matrix $\\boldsymbol{J}$:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{J} = \\begin{bmatrix} \\Delta f(x,z) \\\\ \\Delta g(x,z) \\end{bmatrix} = \\begin{bmatrix} \\frac{\\delta f(x,z)}{\\delta x} & \\frac{\\delta f(x,z)}{\\delta z} \\\\ \\frac{\\delta g(x,z)}{\\delta x} & \\frac{\\delta g(x,z)}{\\delta z} \\end{bmatrix} = \\begin{bmatrix} 6xz & 3x^2 \\\\ 2 & 8z^7 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This matrix is known as the **Jacobian**.\n",
    "\n",
    "Note that here, the Jacobian is presented in the *numerator layout* (i.e numerator on rows). However, in some contexts it will be presented in *denominator layout*."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalising the Jacobian\n",
    "\n",
    "As before, we can generalise the notion of deriving a vector with respect to a vector beyond the simple example.\n",
    "\n",
    "Suppose we have an $n$-length vector of functions $\\boldsymbol{f}$, and an $m$-length vector of variables $\\boldsymbol{x}$. The derivative of $\\boldsymbol{f}$ with respect to $\\boldsymbol{x}$ is then:\n",
    "\n",
    "$$ \\boldsymbol{J} = \\begin{bmatrix} \\frac{\\partial \\boldsymbol{f}}{\\partial x_1} & \\cdots & \\frac{\\partial \\boldsymbol{f}}{\\partial x_n} \\end{bmatrix} = \\begin{bmatrix} \\Delta^T f_1 \\\\ \\vdots \\\\ \\Delta^T f_m \\end{bmatrix} = \\begin{bmatrix} \\frac{\\partial f_1}{\\partial x_1} & \\cdots & \\frac{\\partial f_1}{\\partial x_n} \\\\ \\vdots & \\ddots & \\vdots \\\\ \\frac{\\partial f_m}{\\partial x_1} & \\cdots & \\frac{\\partial f_m}{\\partial x_n} \\end{bmatrix}  $$\n",
    "\n",
    "Where $\\boldsymbol{J}$ is an $m \\times n$ matrix, and $\\Delta^T f_m$ is the transpose (i.e. row vector) of the gradient of $f_m$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Note on Jacobians\n",
    "\n",
    "In many applications, Jacobian matrices turn out to be square matrices (i.e. $m=n$), with off-diagonal entries of 0.\n",
    "\n",
    "When the matrix is square, whether the off-diagonal elements are 0 or not depends on whether we are taking the derivative of a vector *element-wise binary operation*. Using the notation from TMCYNFDL, we denote a binary operation of two vector functions as:\n",
    "\n",
    "$$ \\boldsymbol{f}(\\boldsymbol{w}) \\bigcirc \\boldsymbol{g}(\\boldsymbol{x}) $$\n",
    "\n",
    "In vector form, this is:\n",
    "\n",
    "$$ \\boldsymbol{y} = \\begin{bmatrix} y_1 \\\\ \\vdots \\\\ y_n \\end{bmatrix} = \\begin{bmatrix} f_1(\\boldsymbol{w}) \\bigcirc g_1(\\boldsymbol{x}) \\\\ \\vdots \\\\ f_n(\\boldsymbol{w}) \\bigcirc g_n(\\boldsymbol{x}) \\end{bmatrix} $$\n",
    "\n",
    "The generalised case of the Jacobian with respect to $\\boldsymbol{w}$ is\n",
    "\n",
    "$$ \\boldsymbol{J}_{\\boldsymbol{w}} = \\begin{bmatrix} \\frac{\\partial y_1}{\\partial w_1} (f_1(\\boldsymbol{w}) \\bigcirc g_1(\\boldsymbol{x})) & \\cdots & \\frac{\\partial y_1}{\\partial w_n} (f_1(\\boldsymbol{w}) \\bigcirc g_1(\\boldsymbol{x})) \\\\ \\vdots & \\ddots & \\vdots \\\\ \\frac{\\partial y_n}{\\partial w_1} (f_n(\\boldsymbol{w}) \\bigcirc g_n(\\boldsymbol{x})) & \\cdots & \\frac{\\partial y_n}{\\partial w_n} (f_n(\\boldsymbol{w}) \\bigcirc g_n(\\boldsymbol{x})) \\end{bmatrix} $$\n",
    "\n",
    "Of special interest is the case when $f_i$ and $g_i$ are constants with respect to $w_j$ and $i \\neq j$. In this case:\n",
    "\n",
    "$$ \\frac{\\partial y_i}{\\partial w_j} f_i(\\boldsymbol{w}) \\bigcirc g_i(\\boldsymbol{x}) = 0 $$\n",
    "\n",
    "$f_i$ and $g_i$ will be constant with respect to $w_j$, $i \\neq j$ when $ \\bigcirc $ represents an *element-wise* binary operation.\n",
    "\n",
    "An element-wise binary operation occurs when $f_i$ is solely a function of $w_i$ and $g_i$ is solely a function of $x_i$. Some examples include vector addition, vector subtraction, element-wise multiplication of vectors, and element-wise division of vectors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4 (v3.10.4:9d38120e33, Mar 23 2022, 17:29:05) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "604b3010db54221e39668d7fe34b06214f54669d432870c9edb2f6a865eeb971"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
